{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed + HDFS + Pandas + fastavro\n",
    "======================\n",
    "\n",
    "We read in some CSV data with Pandas, filter it, and write it out as Avro.\n",
    "\n",
    "CSV Bytes on HDFS $\\rightarrow$ Blocks of Bytes in distributed RAM $\\rightarrow$ Pandas DataFrames $\\rightarrow$ Dask DataFrame $\\rightarrow$ Avro-encoded bytes in RAM $\\rightarrow$ Avro Bytes on HDFS\n",
    "\n",
    "1.  `distributed.hdfs.read_binary('/nyc_trip_data_1.csv', hdfs)` $\\rightarrow$ Futures of bytes\n",
    "2.  `dfs = e.map(pd.read_csv, futures_of_bytes` $\\rightarrow$ Futures of pandas dataframes\n",
    "3.  `df = futures_to_collection(dfs)` $\\rightarrow$ dask dataframe\n",
    "4.  `df2 = df[df.passenger_count > 3][...]` $\\rightarrow$ dask dataframe\n",
    "5.  `dfs2 = collection_to_futures(df2)` $\\rightarrow$ Futures of pandas dataframes\n",
    "6.  `bytes = e.map(encode_dataframe_to_avro, dfs)` $\\rightarrow$ Avro encoded bytes in memory\n",
    "7.  `distributed.hdfs.write_binary('/nyc_trip_data_1.csv', futures, hdfs)` $\\rightarrow$ Avro encoded bytes on disk\n",
    "\n",
    "\n",
    "APIs\n",
    "----\n",
    "\n",
    "### HDFS3\n",
    "\n",
    "Read and write bytes to Hadoop File System (HDFS).  User-accessible local Pythonic interface \n",
    "\n",
    "```python\n",
    "with hdfs.open('/nyc/trip_data_1.csv') as f:\n",
    "    df = pd.read_csv(f, nrows=5)\n",
    "```\n",
    "\n",
    "Also includes fancier API for internal use.\n",
    "\n",
    "\n",
    "### Distributed\n",
    "\n",
    "Direct remote execution.  Executes eagerly.\n",
    "\n",
    "1.  `distributed.hdfs.read_binary('/nyc_trip_data_1.csv', hdfs)` $\\rightarrow$ Futures of bytes\n",
    "2.  `e.map(function, futures)` $\\rightarrow$ more futures\n",
    "3.  `distributed.hdfs.write_binary('/nyc_trip_data_1.csv', futures, hdfs)` $\\rightarrow$ bytes on disk\n",
    "\n",
    "\n",
    "### Dask\n",
    "\n",
    "Fancy algorithms.  Pandas-like interface.  Executes lazily. \n",
    "\n",
    "1.  Pandas Futures $\\rightarrow$ dask dataframe\n",
    "2.  Fancy algorithms (filtering, groupby, etc..)\n",
    "3.  Dask dataframe $\\rightarrow$ pandas futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from distributed import Executor, progress, wait\n",
    "from distributed.hdfs import read_binary, write_binary\n",
    "from hdfs3 import HDFileSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = Executor('172.31.9.67:8786')\n",
    "e.restart()\n",
    "hdfs = HDFileSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local use of HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 ms, sys: 3.7 ms, total: 6.56 ms\n",
      "Wall time: 9.69 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with hdfs.open('/nyc/trip_data_1.csv') as f:\n",
    "    df = pd.read_csv(f, nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medallion</th>\n",
       "      <th>hack_license</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_time_in_secs</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89D227B655E5C82AECF13C3F540D4CF4</td>\n",
       "      <td>BA96DE419E711691B9445D6A6307C170</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-01 15:11:48</td>\n",
       "      <td>2013-01-01 15:18:10</td>\n",
       "      <td>4</td>\n",
       "      <td>382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.978165</td>\n",
       "      <td>40.757977</td>\n",
       "      <td>-73.989838</td>\n",
       "      <td>40.751171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0BD7C8F5BA12B88E0B67BED28BEA73D8</td>\n",
       "      <td>9FD8F69F0804BDB5549F40E9DA1BE472</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-06 00:18:35</td>\n",
       "      <td>2013-01-06 00:22:54</td>\n",
       "      <td>1</td>\n",
       "      <td>259</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-74.006683</td>\n",
       "      <td>40.731781</td>\n",
       "      <td>-73.994499</td>\n",
       "      <td>40.750660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0BD7C8F5BA12B88E0B67BED28BEA73D8</td>\n",
       "      <td>9FD8F69F0804BDB5549F40E9DA1BE472</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-05 18:49:41</td>\n",
       "      <td>2013-01-05 18:54:23</td>\n",
       "      <td>1</td>\n",
       "      <td>282</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-74.004707</td>\n",
       "      <td>40.737770</td>\n",
       "      <td>-74.009834</td>\n",
       "      <td>40.726002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DFD2202EE08F7A8DC9A57B02ACB81FE2</td>\n",
       "      <td>51EE87E3205C985EF8431D850C786310</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-07 23:54:15</td>\n",
       "      <td>2013-01-07 23:58:20</td>\n",
       "      <td>2</td>\n",
       "      <td>244</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-73.974602</td>\n",
       "      <td>40.759945</td>\n",
       "      <td>-73.984734</td>\n",
       "      <td>40.759388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DFD2202EE08F7A8DC9A57B02ACB81FE2</td>\n",
       "      <td>51EE87E3205C985EF8431D850C786310</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-07 23:25:03</td>\n",
       "      <td>2013-01-07 23:34:24</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-73.976250</td>\n",
       "      <td>40.748528</td>\n",
       "      <td>-74.002586</td>\n",
       "      <td>40.747868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          medallion                      hack_license  \\\n",
       "0  89D227B655E5C82AECF13C3F540D4CF4  BA96DE419E711691B9445D6A6307C170   \n",
       "1  0BD7C8F5BA12B88E0B67BED28BEA73D8  9FD8F69F0804BDB5549F40E9DA1BE472   \n",
       "2  0BD7C8F5BA12B88E0B67BED28BEA73D8  9FD8F69F0804BDB5549F40E9DA1BE472   \n",
       "3  DFD2202EE08F7A8DC9A57B02ACB81FE2  51EE87E3205C985EF8431D850C786310   \n",
       "4  DFD2202EE08F7A8DC9A57B02ACB81FE2  51EE87E3205C985EF8431D850C786310   \n",
       "\n",
       "  vendor_id  rate_code store_and_fwd_flag      pickup_datetime  \\\n",
       "0       CMT          1                  N  2013-01-01 15:11:48   \n",
       "1       CMT          1                  N  2013-01-06 00:18:35   \n",
       "2       CMT          1                  N  2013-01-05 18:49:41   \n",
       "3       CMT          1                  N  2013-01-07 23:54:15   \n",
       "4       CMT          1                  N  2013-01-07 23:25:03   \n",
       "\n",
       "      dropoff_datetime  passenger_count  trip_time_in_secs  trip_distance  \\\n",
       "0  2013-01-01 15:18:10                4                382            1.0   \n",
       "1  2013-01-06 00:22:54                1                259            1.5   \n",
       "2  2013-01-05 18:54:23                1                282            1.1   \n",
       "3  2013-01-07 23:58:20                2                244            0.7   \n",
       "4  2013-01-07 23:34:24                1                560            2.1   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \n",
       "0        -73.978165        40.757977         -73.989838         40.751171  \n",
       "1        -74.006683        40.731781         -73.994499         40.750660  \n",
       "2        -74.004707        40.737770         -74.009834         40.726002  \n",
       "3        -73.974602        40.759945         -73.984734         40.759388  \n",
       "4        -73.976250        40.748528         -74.002586         40.747868  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed use of HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bytes = read_binary(\"/nyc/trip_data_1.csv\", hdfs=hdfs, delimiter=b'\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: pending, key: read_block-124dce2e35986afe4d3e12779fa217ac>,\n",
       " <Future: status: pending, key: read_block-50ffcbef3b364dc7e023831c3741b20f>,\n",
       " <Future: status: pending, key: read_block-03cec003b46d3749bf92d91254c2fa24>,\n",
       " <Future: status: pending, key: read_block-7c380f28053a466ee35c1be07621aeb5>,\n",
       " <Future: status: pending, key: read_block-ab7e46dc169cf9735372d42287d1d274>,\n",
       " <Future: status: pending, key: read_block-d1ac5bc8646c5664cfcbe08fd7bbeceb>,\n",
       " <Future: status: pending, key: read_block-24de6760635ec9c449f49f3108dbe5b6>,\n",
       " <Future: status: pending, key: read_block-0dff59b6974ae5c30f3ef00ee52c7de2>,\n",
       " <Future: status: pending, key: read_block-b03a108743893919891da58772900066>,\n",
       " <Future: status: pending, key: read_block-0e83a5cfc9b24acec6ae8d2d75333d5c>,\n",
       " <Future: status: pending, key: read_block-0fe84b98b573024540c6b9e99cd2bca9>,\n",
       " <Future: status: pending, key: read_block-1fef52eb4eb08989861f837edd8581cd>,\n",
       " <Future: status: pending, key: read_block-8a411af0346eaa454f92a66e95b272dd>,\n",
       " <Future: status: pending, key: read_block-4b55b7bd22f8aea018d08f44db651d57>,\n",
       " <Future: status: pending, key: read_block-9cddf217bf0841f4db28b8f0948ffdcf>,\n",
       " <Future: status: pending, key: read_block-03e94899504dbbae41f87bee0f2787f8>,\n",
       " <Future: status: pending, key: read_block-e0b0785d70a48c5611fe7e0ecb0b8d78>,\n",
       " <Future: status: pending, key: read_block-b9531134c9911c9201057548655c471f>,\n",
       " <Future: status: finished, key: read_block-83d4a0e767f5bbe54859dd56462b0f3e>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribute pandas functions on bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(b, **kwargs):\n",
    "    bio = BytesIO(b)\n",
    "    return pd.read_csv(bio, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future: status: pending, key: <lambda>-e427adda9ce565bc08437d0e94fb82cb>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = e.submit(lambda bytes: load(bytes, nrows=5), bytes[0])  # get a snippet as a dataframe\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medallion</th>\n",
       "      <th>hack_license</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_time_in_secs</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89D227B655E5C82AECF13C3F540D4CF4</td>\n",
       "      <td>BA96DE419E711691B9445D6A6307C170</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-01 15:11:48</td>\n",
       "      <td>2013-01-01 15:18:10</td>\n",
       "      <td>4</td>\n",
       "      <td>382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.978165</td>\n",
       "      <td>40.757977</td>\n",
       "      <td>-73.989838</td>\n",
       "      <td>40.751171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0BD7C8F5BA12B88E0B67BED28BEA73D8</td>\n",
       "      <td>9FD8F69F0804BDB5549F40E9DA1BE472</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-06 00:18:35</td>\n",
       "      <td>2013-01-06 00:22:54</td>\n",
       "      <td>1</td>\n",
       "      <td>259</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-74.006683</td>\n",
       "      <td>40.731781</td>\n",
       "      <td>-73.994499</td>\n",
       "      <td>40.750660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0BD7C8F5BA12B88E0B67BED28BEA73D8</td>\n",
       "      <td>9FD8F69F0804BDB5549F40E9DA1BE472</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-05 18:49:41</td>\n",
       "      <td>2013-01-05 18:54:23</td>\n",
       "      <td>1</td>\n",
       "      <td>282</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-74.004707</td>\n",
       "      <td>40.737770</td>\n",
       "      <td>-74.009834</td>\n",
       "      <td>40.726002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DFD2202EE08F7A8DC9A57B02ACB81FE2</td>\n",
       "      <td>51EE87E3205C985EF8431D850C786310</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-07 23:54:15</td>\n",
       "      <td>2013-01-07 23:58:20</td>\n",
       "      <td>2</td>\n",
       "      <td>244</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-73.974602</td>\n",
       "      <td>40.759945</td>\n",
       "      <td>-73.984734</td>\n",
       "      <td>40.759388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DFD2202EE08F7A8DC9A57B02ACB81FE2</td>\n",
       "      <td>51EE87E3205C985EF8431D850C786310</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-07 23:25:03</td>\n",
       "      <td>2013-01-07 23:34:24</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-73.976250</td>\n",
       "      <td>40.748528</td>\n",
       "      <td>-74.002586</td>\n",
       "      <td>40.747868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          medallion                      hack_license  \\\n",
       "0  89D227B655E5C82AECF13C3F540D4CF4  BA96DE419E711691B9445D6A6307C170   \n",
       "1  0BD7C8F5BA12B88E0B67BED28BEA73D8  9FD8F69F0804BDB5549F40E9DA1BE472   \n",
       "2  0BD7C8F5BA12B88E0B67BED28BEA73D8  9FD8F69F0804BDB5549F40E9DA1BE472   \n",
       "3  DFD2202EE08F7A8DC9A57B02ACB81FE2  51EE87E3205C985EF8431D850C786310   \n",
       "4  DFD2202EE08F7A8DC9A57B02ACB81FE2  51EE87E3205C985EF8431D850C786310   \n",
       "\n",
       "  vendor_id  rate_code store_and_fwd_flag      pickup_datetime  \\\n",
       "0       CMT          1                  N  2013-01-01 15:11:48   \n",
       "1       CMT          1                  N  2013-01-06 00:18:35   \n",
       "2       CMT          1                  N  2013-01-05 18:49:41   \n",
       "3       CMT          1                  N  2013-01-07 23:54:15   \n",
       "4       CMT          1                  N  2013-01-07 23:25:03   \n",
       "\n",
       "      dropoff_datetime  passenger_count  trip_time_in_secs  trip_distance  \\\n",
       "0  2013-01-01 15:18:10                4                382            1.0   \n",
       "1  2013-01-06 00:22:54                1                259            1.5   \n",
       "2  2013-01-05 18:54:23                1                282            1.1   \n",
       "3  2013-01-07 23:58:20                2                244            0.7   \n",
       "4  2013-01-07 23:34:24                1                560            2.1   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \n",
       "0        -73.978165        40.757977         -73.989838         40.751171  \n",
       "1        -74.006683        40.731781         -73.994499         40.750660  \n",
       "2        -74.004707        40.737770         -74.009834         40.726002  \n",
       "3        -73.974602        40.759945         -73.984734         40.759388  \n",
       "4        -73.976250        40.748528         -74.002586         40.747868  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = head.result()  # bring result to local process\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'medallion', u'hack_license', u'vendor_id', u'rate_code',\n",
       "       u'store_and_fwd_flag', u'pickup_datetime', u'dropoff_datetime',\n",
       "       u'passenger_count', u'trip_time_in_secs', u'trip_distance',\n",
       "       u'pickup_longitude', u'pickup_latitude', u'dropoff_longitude',\n",
       "       u'dropoff_latitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head.columns  # we need these to help the other blocks of bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs = [e.submit(load, bytes[0])] + e.map(load, bytes[1:], names=head.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask DataFrame\n",
    "\n",
    "We unite all of the scattered pandas dataframes into one logical dask dataframe.  No computation or data movement occurs.  This is purely administrative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: pending, key: load-b8649f9b28fc324cae1306bc4e793c3c>,\n",
       " <Future: status: pending, key: load-5ac8033eecc178ab201ba7699a595318>,\n",
       " <Future: status: pending, key: load-0ca9a1f39834fe75faee682307d91c2f>,\n",
       " <Future: status: pending, key: load-3fc8c8edf429f81a366ae221eb168cfa>,\n",
       " <Future: status: pending, key: load-7ea2d47492316df297bb5cef8a978a41>,\n",
       " <Future: status: pending, key: load-0ecb80fdd9e2e21e898adeb4c209473a>,\n",
       " <Future: status: pending, key: load-b5f0124dc4cf699be5fa67ca29b5f536>,\n",
       " <Future: status: pending, key: load-ee654c4dd01d0aa1589d522b322d7f32>,\n",
       " <Future: status: pending, key: load-e813e8b71c1bf16cf48c8043207d443f>,\n",
       " <Future: status: pending, key: load-0d71842dfd07b883b9f1f630a575439f>,\n",
       " <Future: status: pending, key: load-6975eb8a64821e2dfce8a942dda318e5>,\n",
       " <Future: status: pending, key: load-db1d8ff2bdf57fa973fc169c238fcc83>,\n",
       " <Future: status: pending, key: load-b5d2dc2ef86fb81790f609aea2c3d0b8>,\n",
       " <Future: status: pending, key: load-8963dd9c76975f5d3e9ea22e3c6c5d3d>,\n",
       " <Future: status: pending, key: load-63d1583133ebea65dff8be6ab3d42d6b>,\n",
       " <Future: status: pending, key: load-3abcb49a6e019e0c0798b6eb121325bf>,\n",
       " <Future: status: pending, key: load-557b7e55966d346846fe7b4ee9d4d340>,\n",
       " <Future: status: pending, key: load-d8966c36aeccce8e46711cf9c08f57f1>,\n",
       " <Future: status: pending, key: load-d277a48fd5b6307be0323231caa584a6>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting global dask scheduler to use distributed\n"
     ]
    }
   ],
   "source": [
    "from distributed.collections import futures_to_dask_dataframe\n",
    "ddf = futures_to_dask_dataframe(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.dataframe.core.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medallion</th>\n",
       "      <th>hack_license</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_time_in_secs</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89D227B655E5C82AECF13C3F540D4CF4</td>\n",
       "      <td>BA96DE419E711691B9445D6A6307C170</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-01 15:11:48</td>\n",
       "      <td>2013-01-01 15:18:10</td>\n",
       "      <td>4</td>\n",
       "      <td>382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-73.978165</td>\n",
       "      <td>40.757977</td>\n",
       "      <td>-73.989838</td>\n",
       "      <td>40.751171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0BD7C8F5BA12B88E0B67BED28BEA73D8</td>\n",
       "      <td>9FD8F69F0804BDB5549F40E9DA1BE472</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-06 00:18:35</td>\n",
       "      <td>2013-01-06 00:22:54</td>\n",
       "      <td>1</td>\n",
       "      <td>259</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-74.006683</td>\n",
       "      <td>40.731781</td>\n",
       "      <td>-73.994499</td>\n",
       "      <td>40.750660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0BD7C8F5BA12B88E0B67BED28BEA73D8</td>\n",
       "      <td>9FD8F69F0804BDB5549F40E9DA1BE472</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-05 18:49:41</td>\n",
       "      <td>2013-01-05 18:54:23</td>\n",
       "      <td>1</td>\n",
       "      <td>282</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-74.004707</td>\n",
       "      <td>40.737770</td>\n",
       "      <td>-74.009834</td>\n",
       "      <td>40.726002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DFD2202EE08F7A8DC9A57B02ACB81FE2</td>\n",
       "      <td>51EE87E3205C985EF8431D850C786310</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-07 23:54:15</td>\n",
       "      <td>2013-01-07 23:58:20</td>\n",
       "      <td>2</td>\n",
       "      <td>244</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-73.974602</td>\n",
       "      <td>40.759945</td>\n",
       "      <td>-73.984734</td>\n",
       "      <td>40.759388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DFD2202EE08F7A8DC9A57B02ACB81FE2</td>\n",
       "      <td>51EE87E3205C985EF8431D850C786310</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-01-07 23:25:03</td>\n",
       "      <td>2013-01-07 23:34:24</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-73.976250</td>\n",
       "      <td>40.748528</td>\n",
       "      <td>-74.002586</td>\n",
       "      <td>40.747868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          medallion                      hack_license  \\\n",
       "0  89D227B655E5C82AECF13C3F540D4CF4  BA96DE419E711691B9445D6A6307C170   \n",
       "1  0BD7C8F5BA12B88E0B67BED28BEA73D8  9FD8F69F0804BDB5549F40E9DA1BE472   \n",
       "2  0BD7C8F5BA12B88E0B67BED28BEA73D8  9FD8F69F0804BDB5549F40E9DA1BE472   \n",
       "3  DFD2202EE08F7A8DC9A57B02ACB81FE2  51EE87E3205C985EF8431D850C786310   \n",
       "4  DFD2202EE08F7A8DC9A57B02ACB81FE2  51EE87E3205C985EF8431D850C786310   \n",
       "\n",
       "  vendor_id  rate_code store_and_fwd_flag      pickup_datetime  \\\n",
       "0       CMT          1                  N  2013-01-01 15:11:48   \n",
       "1       CMT          1                  N  2013-01-06 00:18:35   \n",
       "2       CMT          1                  N  2013-01-05 18:49:41   \n",
       "3       CMT          1                  N  2013-01-07 23:54:15   \n",
       "4       CMT          1                  N  2013-01-07 23:25:03   \n",
       "\n",
       "      dropoff_datetime  passenger_count  trip_time_in_secs  trip_distance  \\\n",
       "0  2013-01-01 15:18:10                4                382            1.0   \n",
       "1  2013-01-06 00:22:54                1                259            1.5   \n",
       "2  2013-01-05 18:54:23                1                282            1.1   \n",
       "3  2013-01-07 23:58:20                2                244            0.7   \n",
       "4  2013-01-07 23:34:24                1                560            2.1   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \n",
       "0        -73.978165        40.757977         -73.989838         40.751171  \n",
       "1        -74.006683        40.731781         -73.994499         40.750660  \n",
       "2        -74.004707        40.737770         -74.009834         40.726002  \n",
       "3        -73.974602        40.759945         -73.984734         40.759388  \n",
       "4        -73.976250        40.748528         -74.002586         40.747868  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter\n",
    "\n",
    "Lets say that we only care about trips with lots of passengers.  We use `dask.dataframe` to apply pandas syntax to all of our data at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_time_in_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 15:11:48</td>\n",
       "      <td>4</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013-01-07 18:05:36</td>\n",
       "      <td>4</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2013-01-05 03:20:28</td>\n",
       "      <td>4</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2013-01-05 19:52:03</td>\n",
       "      <td>4</td>\n",
       "      <td>959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2013-01-13 04:36:00</td>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pickup_datetime  passenger_count  trip_time_in_secs\n",
       "0    2013-01-01 15:11:48                4                382\n",
       "21   2013-01-07 18:05:36                4               1094\n",
       "38   2013-01-05 03:20:28                4               1387\n",
       "129  2013-01-05 19:52:03                4                959\n",
       "157  2013-01-13 04:36:00                5                600"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf2 = ddf[ddf.passenger_count > 3][['pickup_datetime', 'passenger_count', 'trip_time_in_secs']]\n",
    "ddf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert the `dask.dataframe` back to futures to that we can use lower-level tools again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: pending, key: finalize-646cbe1ccfb17f08a6c6515c446a6c7d>,\n",
       " <Future: status: pending, key: finalize-b666aea0901cb3634db36a38cd80d9f3>,\n",
       " <Future: status: pending, key: finalize-614646bfb363bafda351735c633e1d75>,\n",
       " <Future: status: pending, key: finalize-53562c7e193fa270a008840dd2dbca9b>,\n",
       " <Future: status: pending, key: finalize-960ded82f71aa4cca0c9fc22f4fd10a0>,\n",
       " <Future: status: pending, key: finalize-a7ee9b8a77ff418f11c4968d7490e896>,\n",
       " <Future: status: pending, key: finalize-5531b5d3d70154085054d505d5ccd72a>,\n",
       " <Future: status: pending, key: finalize-911fdcf2e8e203ac1871ad15373329cc>,\n",
       " <Future: status: pending, key: finalize-20da7bf426dcd983b5a89de2c8bd3b31>,\n",
       " <Future: status: pending, key: finalize-98cc5e737154c306bffac25e4a587584>,\n",
       " <Future: status: pending, key: finalize-ec4b234a83ff5fb35759d5392f7d1f7f>,\n",
       " <Future: status: pending, key: finalize-71b16610d8e01a7cab05223055c4148b>,\n",
       " <Future: status: pending, key: finalize-30d52a7035bd97a0cf65f26c1059735f>,\n",
       " <Future: status: pending, key: finalize-55ca0da4e5de2047ac8a5633a95aa7a5>,\n",
       " <Future: status: pending, key: finalize-df163233bb4435190b165bd614c4e096>,\n",
       " <Future: status: pending, key: finalize-e9a678e361f64cea3785596da276014b>,\n",
       " <Future: status: pending, key: finalize-236ec67749d6172393461cc5bed2dac9>,\n",
       " <Future: status: pending, key: finalize-5eb3a3077ed879af18463ffb10ee911e>,\n",
       " <Future: status: pending, key: finalize-3ac2ec24dcc16ed46bfc2d5d971ef78b>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs2 = e.compute(*ddf2.to_imperative())  \n",
    "dfs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Avro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate schema\n",
    "\n",
    "Cyavro has a nice utility to generate an Avro schema from a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'fields': [{u'name': u'pickup_datetime', u'type': u'string'},\n",
       "  {u'name': u'passenger_count', u'type': u'long'},\n",
       "  {u'name': u'trip_time_in_secs', u'type': u'long'}],\n",
       " u'name': u'AutoGen',\n",
       " u'namespace': u'com.maxpoint.cyavro.autogenerated',\n",
       " u'type': u'record'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import cyavro\n",
    "schema = json.loads(cyavro.infer_avro_schema_for_dataframe(ddf2.head()))\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode to bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_dataframe_to_avro(df, schema=None):\n",
    "    \"\"\" Encode a Pandas DataFrame to an Avro file \n",
    "    \n",
    "    Returns bytes\n",
    "    \"\"\"\n",
    "    from fastavro import writer\n",
    "    if schema is None:\n",
    "        import cyavro, json\n",
    "        schema = json.loads(cyavro.infer_avro_schema_for_dataframe(df))\n",
    "    bio = BytesIO()\n",
    "    records = df.to_dict(orient='records')\n",
    "    writer(bio, schema, records)\n",
    "    return bio.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = e.map(encode_dataframe_to_avro, dfs2, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: pending, key: encode_dataframe_to_avro-a39d00a7909711e3c868c0d45541e68e>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-8e323fd4685aef616c005bc5f7666818>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-2f63aab85962af566331abd94644447e>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-2c2c6d8b5cc12301a051ff22fe4ff0c8>,\n",
       " <Future: status: finished, key: encode_dataframe_to_avro-5e6e228231ab05ba31c38655d675e462>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-cde3d10301d698b200f3b2902001ede5>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-bcd91d9d41ebfc2afb39e09712f00f6f>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-7cb5f81d3558eb0dfc091d3bc787fbf6>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-492dfaa9ec0e5577a2743ced45f5f432>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-c760f38b8d53b2ba38ea0553274e20c8>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-1fc39dd7b9b057379e8d80b8f53cb39e>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-616274ecc2d7d3c58bf353a8515fada6>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-f0d1d6ac1f8775341c57bd3b44524bd7>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-e8766207f1f34f56f66467b535b28767>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-5af7a810d8f388af424d73aa1b20633f>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-216717e6b346495bb00940d1b796c9b3>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-b86a6d5f23caa44ed080654fd9f5dedf>,\n",
       " <Future: status: pending, key: encode_dataframe_to_avro-ed8bad43c9349979b2245492161b6a2a>,\n",
       " <Future: status: finished, key: encode_dataframe_to_avro-6780b0de8500fb0457ed8876ad6e6a7c>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write bytes to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if hdfs.exists('/nyc/avro/'):\n",
    "    hdfs.rm('/nyc/avro/')\n",
    "hdfs.mkdir('/nyc/avro/')\n",
    "writes = write_binary('/nyc/avro/trip.*.avro', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: status: pending, key: write-febc6806ef20c45e4f96b626f5bbe4d1>,\n",
       " <Future: status: pending, key: write-d87354ec5f686aa3de20805378e3d4d7>,\n",
       " <Future: status: pending, key: write-42966cd2e138cd472d2f4f1115d3d66d>,\n",
       " <Future: status: finished, key: write-8ac448dc47041428c2eb6ad387faf18a>,\n",
       " <Future: status: finished, key: write-961be39e4effb2ee5a68a2bd86a0d463>,\n",
       " <Future: status: finished, key: write-b107382a3c5d90c2c70fd9b89a342cdd>,\n",
       " <Future: status: pending, key: write-c16da581d1fdcc21c727a4909c644c0c>,\n",
       " <Future: status: pending, key: write-57a75dc8320ba6d2f1ed3b2e653c7a1a>,\n",
       " <Future: status: pending, key: write-5c49480f4644a6334c713699deac9bb0>,\n",
       " <Future: status: pending, key: write-fc35ff9ed626d4c4543b70c70c542cc2>,\n",
       " <Future: status: pending, key: write-d1143fc7247027403ac6f0d5926dc779>,\n",
       " <Future: status: pending, key: write-1def86ccb4d5cbf47a7c210a77336bad>,\n",
       " <Future: status: pending, key: write-02d31212e560bb940b4e6f331606e87b>,\n",
       " <Future: status: pending, key: write-1ec663ace149a54b6b58caa3291cf586>,\n",
       " <Future: status: pending, key: write-1638011b62a121fd28d682dc32e7ad2c>,\n",
       " <Future: status: pending, key: write-67226affc0c37197088cfe43f2212725>,\n",
       " <Future: status: pending, key: write-5a27bb1dd8cc628e822ea36b0c12617e>,\n",
       " <Future: status: finished, key: write-091829576bafa2e45a951ef4c82213d7>,\n",
       " <Future: status: pending, key: write-862f8f28e625f9af2b9a8477ad5c1dfb>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "progress(writes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locally verify avro file works\n",
    "\n",
    "We do this using the `hdfs3` library from the head node.  This isn't distributed, data-local, or maximally efficient, but its great for simple checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wait(writes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fastavro\n",
    "f = hdfs.open('/nyc/avro/trip.0.avro')\n",
    "reader = fastavro.reader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'passenger_count': 4,\n",
       " u'pickup_datetime': u'2013-01-01 15:11:48',\n",
       " u'trip_time_in_secs': 382}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'passenger_count': 4,\n",
       " u'pickup_datetime': u'2013-01-07 18:05:36',\n",
       " u'trip_time_in_secs': 1094}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdfs.rm('/nyc/avro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

