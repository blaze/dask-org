{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word count with hdfs3, distributed, and dask\n",
    "\n",
    "In this example, we count the number of words in text files (Enron email dataset - 6.4 GB) stored in HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "import distributed\n",
    "import hdfs3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1) Word count with hdfs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdfs = hdfs3.HDFileSystem('ip-172-31-56-96', port=8020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate list of foldernames and filenames in /tmp/enron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dirnames = [x['name'] for x in hdfs.ls('/tmp/enron')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'/tmp/enron/edrm-enron-v2_allen-p_xml.zip',\n",
       " b'/tmp/enron/edrm-enron-v2_arnold-j_xml.zip',\n",
       " b'/tmp/enron/edrm-enron-v2_arora-h_xml.zip',\n",
       " b'/tmp/enron/edrm-enron-v2_badeer-r_xml.zip',\n",
       " b'/tmp/enron/edrm-enron-v2_bailey-s_xml.zip']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirnames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = [x.decode('utf-8') + '/merged.txt' for x in dirnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/enron/edrm-enron-v2_allen-p_xml.zip/merged.txt',\n",
       " '/tmp/enron/edrm-enron-v2_arnold-j_xml.zip/merged.txt',\n",
       " '/tmp/enron/edrm-enron-v2_arora-h_xml.zip/merged.txt',\n",
       " '/tmp/enron/edrm-enron-v2_badeer-r_xml.zip/merged.txt',\n",
       " '/tmp/enron/edrm-enron-v2_bailey-s_xml.zip/merged.txt']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print first 10 lines of first file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: Tue, 26 Sep 2000 09:26:00 -0700 (PDT)\r\n",
      "From: Phillip K Allen\r\n",
      "To: pallen70@hotmail.com\r\n",
      "Subject: Investment Structure\r\n",
      "X-SDOC: 948896\r\n",
      "X-ZLID: zl-edrm-enron-v2-allen-p-1713.eml\r\n",
      "\r\n",
      "---------------------- Forwarded by Phillip K Allen/HOU/ECT on 09/26/2000 \r\n",
      "04:26 PM ---------------------------\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "with hdfs.open(filenames[0]) as f:\n",
    "    f.encoding = 'utf-8'\n",
    "    [print(f.readline()) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_words(filename, encoding):\n",
    "    with hdfs.open(filename) as f:\n",
    "        f.encoding = encoding\n",
    "        count = 0\n",
    "        all_lines = f.readlines()\n",
    "        for line in all_lines:\n",
    "            words = line.split()\n",
    "            count += len(words)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count words in first file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.27 s, sys: 123 ms, total: 3.39 s\n",
      "Wall time: 3.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13099980"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "count_words('/tmp/enron/edrm-enron-v2_allen-p_xml.zip/merged.txt', 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count words in all (readable) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "wordcounts = {}\n",
    "for filename in filenames:\n",
    "    try:\n",
    "        wordcounts[filename] = count_words(filename, 'utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        wordcounts[filename] = 'Encoding error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Encoding error', 4004560, 5814482, 13099980, 25683415, 416404, 'Encoding error', 7247270, 290147, 4179444, 6141434, 5803416, 1077750, 'Encoding error', 'Encoding error', 'Encoding error', 4746877, 'Encoding error', 7490781, 602964, 3390924, 4414609, 13706115, 1965278, 'Encoding error', 2423343, 'Encoding error', 1297348, 'Encoding error', 551252, 3212038, 1901115, 646054, 'Encoding error', 'Encoding error', 'Encoding error', 'Encoding error', 'Encoding error', 'Encoding error', 0, 'Encoding error', 0, 0, 'Encoding error', 822377, 'Encoding error', 'Encoding error', 'Encoding error', 'Encoding error', 940670, 10179741, 1941178, 'Encoding error', 0, 732104, 6019540, 327602, 741113, 833143, 'Encoding error', 859418, 1214718, 380978, 'Encoding error', 349008, 'Encoding error', 1241517, 'Encoding error', 653546, 'Encoding error', 2309593, 'Encoding error', 'Encoding error', 1287530, 'Encoding error', 135598, 712714, 'Encoding error', 2010407, 1296974, 2176585, 5445575, 17209358, 1386230, 5736422, 0, 9978422, 0, 640160, 34052622, 942422, 454763, 'Encoding error', 3787166, 3073065, 'Encoding error', 'Encoding error', 3798929, 'Encoding error', 'Encoding error', 222069, 'Encoding error', 3463107, 'Encoding error', 7071894, 1082150, 748549, 1675517, 2605960, 1298290, 6218404, 1130924, 0, 983216, 3006520, 'Encoding error', 1405998, 1302679, 1599893, 3271284, 'Encoding error', 'Encoding error', 'Encoding error', 2552968, 0, 6195025, 826188, 690003, 2993343, 'Encoding error', 2198541, 4227672, 'Encoding error', 'Encoding error', 236457, 1907746, 'Encoding error', 1910725, 'Encoding error', 435731, 15836636, 8222368, 'Encoding error', 648040, 10528904, 'Encoding error', 1787279, 'Encoding error', 'Encoding error', 1502415, 779589, 'Encoding error', 2674950, 999658, 'Encoding error', 639765, 'Encoding error', 1778714, 3487505, 1482517, 8287835])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcounts.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363695216"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x for x in wordcounts.values() if isinstance(x, int)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing API functionality?\n",
    "\n",
    "* wanted to list only filenames (and not other HDFS file info)\n",
    "* wanted to load all text files in subdirs (glob like /tmp/enron/*/*.txt)\n",
    "* wanted to set encoding in .open() method\n",
    "* wanted to easily read head of large text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2) Word count with hdfs3 + distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing API functionality?\n",
    "\n",
    "* .head() in distributed or dask?\n",
    "* need a futures_to_bag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
